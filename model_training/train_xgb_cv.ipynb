{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c604c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helper import log_multi_target_run, transform_targets, compute_metrics\n",
    "from tiny_mlflow import log_multi_target_run_local\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import cudf\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROP = ['id']\n",
    "TARGETS = [\"n2o\", \"no3\", \"yield\", \"soc\"]\n",
    "\n",
    "gdf = cudf.read_parquet(\"../data_processing/data/df_WIWH_training.parquet\")\n",
    "\n",
    "gdf = gdf[:1000]\n",
    "\n",
    "X_train = gdf.drop(columns=TARGETS)\n",
    "y_train = gdf[TARGETS]\n",
    "\n",
    "del gdf\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b69b559e-8fa4-4427-b798-de6e2a260b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "\n",
    "\n",
    "def _to_serializable(obj):\n",
    "    \"\"\"Recursively convert numpy types to plain Python types for JSON.\"\"\"\n",
    "    if isinstance(obj, (np.floating, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.integer, np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _to_serializable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_to_serializable(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "# assumes:\n",
    "# - TARGETS is defined\n",
    "# - transform_targets, compute_metrics, log_multi_target_run,\n",
    "#   log_multi_target_run_local, and xgboost (as xgb) are imported\n",
    "\n",
    "\n",
    "def train_xgb_models_cv(\n",
    "    X_cudf,\n",
    "    y_cudf,\n",
    "    n_splits=5,\n",
    "    group_col=\"id\",          # used only for splitting, not as feature\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    num_boost_round=10_000,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=False,\n",
    "    log_to_mlflow=False,\n",
    "    base_dir=\"experiments_cv\",\n",
    "    experiment_name=\"multi_target_xgb_cv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Cross validate XGBoost models for multiple targets and save everything in experiments_cv.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_cudf : cuDF DataFrame\n",
    "        Features plus possibly an id column used only for grouping.\n",
    "    y_cudf : cuDF DataFrame\n",
    "        Targets with columns matching TARGETS.\n",
    "    \"\"\"\n",
    "\n",
    "    t_global_start = time.time()\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    n_samples = len(X_cudf)\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    # 1 - handle grouping column\n",
    "    groups = None\n",
    "    feature_cols = list(X_cudf.columns)\n",
    "\n",
    "    if group_col is not None:\n",
    "        if group_col in feature_cols:\n",
    "            # take groups from this column\n",
    "            groups = X_cudf[group_col].to_pandas().values\n",
    "            # remove id from feature columns so it is not used as a feature\n",
    "            feature_cols = [c for c in feature_cols if c != group_col]\n",
    "            print(f\"[CV] Using '{group_col}' as group column and dropping it from features\")\n",
    "        else:\n",
    "            # group_col specified but not in X_cudf\n",
    "            # in that case we fall back to plain KFold\n",
    "            print(\n",
    "                f\"[CV] Warning: group_col='{group_col}' not in X_cudf columns. \"\n",
    "                \"Using standard KFold without grouping.\"\n",
    "            )\n",
    "            group_col = None\n",
    "\n",
    "    # 2 - choose splitter\n",
    "    if group_col is not None and groups is not None:\n",
    "        print(f\"[CV] Using GroupKFold over group_col='{group_col}'\")\n",
    "        splitter = GroupKFold(n_splits=n_splits)\n",
    "        split_iter = splitter.split(indices, groups=groups)\n",
    "        split_name = f\"GroupKFold(n_splits={n_splits}, group_col='{group_col}')\"\n",
    "    else:\n",
    "        print(\"[CV] Using standard KFold\")\n",
    "        splitter = KFold(\n",
    "            n_splits=n_splits,\n",
    "            shuffle=shuffle,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        split_iter = splitter.split(indices)\n",
    "        split_name = (\n",
    "            f\"KFold(n_splits={n_splits}, shuffle={shuffle}, random_state={random_state})\"\n",
    "        )\n",
    "\n",
    "    print(f\"[CV] Starting XGBoost cross validation\")\n",
    "    print(f\"[CV] Splitter: {split_name}\")\n",
    "    print(f\"[CV] Total samples: {n_samples}\")\n",
    "    print(f\"[CV] Targets: {TARGETS}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 3 - target transforms\n",
    "    print(\"[CV] Fitting target transformations on full dataset ...\")\n",
    "    t_tr_start = time.time()\n",
    "    y_orig_np, y_trans_np, transformers = transform_targets(y_cudf)\n",
    "    print(f\"[CV] Target transformations done in {time.time() - t_tr_start:.1f}s\")\n",
    "\n",
    "    # 4 - build feature matrix on CPU without id\n",
    "    print(\"[CV] Moving features to CPU (numpy float32) ...\")\n",
    "    t_x_start = time.time()\n",
    "\n",
    "    # only use feature_cols, which does not contain group_col/id\n",
    "    X_features_cudf = X_cudf[feature_cols]\n",
    "    X_all_np = X_features_cudf.to_numpy().astype(\"float32\")\n",
    "    feature_names = feature_cols\n",
    "\n",
    "    print(\n",
    "        f\"[CV] X feature shape (without group_col): {X_all_np.shape}, \"\n",
    "        f\"converted in {time.time() - t_x_start:.1f}s\"\n",
    "    )\n",
    "    print(f\"[CV] Feature columns used: {feature_names}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 5 - base xgb params\n",
    "    base_params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"sampling_method\": \"gradient_based\",\n",
    "        \"max_bin\": 256,\n",
    "        \"max_depth\": 9,\n",
    "        \"min_child_weight\": 48,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.6,\n",
    "        \"learning_rate\": 0.013556,\n",
    "        \"gamma\": 1.074052,\n",
    "        \"reg_alpha\": 0.151021,\n",
    "        \"reg_lambda\": 11.097351,\n",
    "    }\n",
    "\n",
    "    fold_models = {target: [] for target in TARGETS}\n",
    "    cv_results = {target: {\"fold_metrics\": []} for target in TARGETS}\n",
    "    splits_info = []\n",
    "\n",
    "    # 6 - CV loop\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(split_iter, start=1):\n",
    "        t_fold_start = time.time()\n",
    "        n_train = len(train_idx)\n",
    "        n_val = len(val_idx)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\n",
    "            f\"[CV] Fold {fold_idx}/{n_splits} - \"\n",
    "            f\"train samples: {n_train}, val samples: {n_val}\"\n",
    "        )\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        splits_info.append(\n",
    "            {\n",
    "                \"fold\": fold_idx,\n",
    "                \"n_train\": int(n_train),\n",
    "                \"n_val\": int(n_val),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        X_train_np = X_all_np[train_idx]\n",
    "        X_val_np = X_all_np[val_idx]\n",
    "\n",
    "        models_fold = {}\n",
    "        metrics_fold = {}\n",
    "\n",
    "        for target in TARGETS:\n",
    "            t_target_start = time.time()\n",
    "            print(f\"[CV][Fold {fold_idx}] Target '{target}' - preparing data ...\")\n",
    "\n",
    "            y_train_trans = y_trans_np[target][train_idx].astype(\"float32\")\n",
    "            y_val_trans = y_trans_np[target][val_idx].astype(\"float32\")\n",
    "            y_val_orig = y_orig_np[target][val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(\n",
    "                X_train_np,\n",
    "                label=y_train_trans,\n",
    "                feature_names=feature_names,\n",
    "            )\n",
    "            dval = xgb.DMatrix(\n",
    "                X_val_np,\n",
    "                label=y_val_trans,\n",
    "                feature_names=feature_names,\n",
    "            )\n",
    "\n",
    "            print(f\"[CV][Fold {fold_idx}] Target '{target}' - training XGBoost ...\")\n",
    "\n",
    "            params = dict(base_params)\n",
    "            model_name = f\"xgb_v1_cv_fold{fold_idx}_{target}\"\n",
    "\n",
    "            evals = [(dtrain, \"train\"), (dval, \"valid\")]\n",
    "\n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round=num_boost_round,\n",
    "                evals=evals,\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                verbose_eval=verbose_eval,\n",
    "            )\n",
    "\n",
    "            fold_models[target].append(booster)\n",
    "            models_fold[target] = booster\n",
    "\n",
    "            preds_val_trans = booster.predict(dval)\n",
    "\n",
    "            fold_metrics, _ = compute_metrics(\n",
    "                target,\n",
    "                preds_val_trans,\n",
    "                y_val_orig,\n",
    "                transformers[target],\n",
    "                model_name,\n",
    "            )\n",
    "            cv_results[target][\"fold_metrics\"].append(\n",
    "                {\"fold\": fold_idx, **fold_metrics}\n",
    "            )\n",
    "            metrics_fold[target] = fold_metrics\n",
    "\n",
    "            print(\n",
    "                f\"[CV][Fold {fold_idx}] Target '{target}' done in \"\n",
    "                f\"{time.time() - t_target_start:.1f}s \"\n",
    "                f\"| val RMSE: {fold_metrics.get('rmse', float('nan')):.4f} \"\n",
    "                f\"MAE: {fold_metrics.get('mae', float('nan')):.4f} \"\n",
    "                f\"R2: {fold_metrics.get('r2', float('nan')):.4f}\"\n",
    "            )\n",
    "\n",
    "            # save model for this fold and target\n",
    "            model_dir = os.path.join(\n",
    "                base_dir, experiment_name, f\"fold_{fold_idx}\", \"models\"\n",
    "            )\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            model_path = os.path.join(model_dir, f\"{target}.json\")\n",
    "            booster.save_model(model_path)\n",
    "\n",
    "        # per fold logging\n",
    "        run_name = f\"xgb_cv_fold{fold_idx}\"\n",
    "        if log_to_mlflow:\n",
    "            log_multi_target_run(\n",
    "                model_family_name=\"xgboost\",\n",
    "                models=models_fold,\n",
    "                metrics=metrics_fold,\n",
    "                feature_names=feature_names,\n",
    "                transformers=transformers,\n",
    "                experiment_name=experiment_name,\n",
    "                run_name=run_name,\n",
    "            )\n",
    "        else:\n",
    "            log_multi_target_run_local(\n",
    "                model_family_name=\"xgboost\",\n",
    "                models=models_fold,\n",
    "                metrics=metrics_fold,\n",
    "                feature_names=feature_names,\n",
    "                transformers=transformers,\n",
    "                experiment_name=experiment_name,\n",
    "                run_name=run_name,\n",
    "                base_dir=base_dir,\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            f\"[CV] Completed fold {fold_idx}/{n_splits} in \"\n",
    "            f\"{time.time() - t_fold_start:.1f}s\"\n",
    "        )\n",
    "\n",
    "    # 7 - aggregate metrics\n",
    "    print(\"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[CV] Aggregating metrics across folds\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for target in TARGETS:\n",
    "        rmse_list = [m[\"rmse\"] for m in cv_results[target][\"fold_metrics\"]]\n",
    "        mae_list = [m[\"mae\"] for m in cv_results[target][\"fold_metrics\"]]\n",
    "        r2_list = [m[\"r2\"] for m in cv_results[target][\"fold_metrics\"]]\n",
    "\n",
    "        mean_rmse = float(np.mean(rmse_list))\n",
    "        std_rmse = float(np.std(rmse_list))\n",
    "        mean_mae = float(np.mean(mae_list))\n",
    "        std_mae = float(np.std(mae_list))\n",
    "        mean_r2 = float(np.mean(r2_list))\n",
    "        std_r2 = float(np.std(r2_list))\n",
    "\n",
    "        cv_results[target][\"mean_metrics\"] = {\n",
    "            \"rmse\": mean_rmse,\n",
    "            \"mae\": mean_mae,\n",
    "            \"r2\": mean_r2,\n",
    "        }\n",
    "        cv_results[target][\"std_metrics\"] = {\n",
    "            \"rmse\": std_rmse,\n",
    "            \"mae\": std_mae,\n",
    "            \"r2\": std_r2,\n",
    "        }\n",
    "\n",
    "        print(\n",
    "            f\"[CV][{target}] \"\n",
    "            f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f} | \"\n",
    "            f\"MAE: {mean_mae:.4f} ± {std_mae:.4f} | \"\n",
    "            f\"R2: {mean_r2:.4f} ± {std_r2:.4f}\"\n",
    "        )\n",
    "\n",
    "    # 8 - save summary\n",
    "    summary_dir = os.path.join(base_dir, experiment_name, \"summary\")\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "\n",
    "    summary_payload = {\n",
    "        \"n_splits\": n_splits,\n",
    "        \"splitter\": split_name,\n",
    "        \"targets\": TARGETS,\n",
    "        \"splits_info\": splits_info,\n",
    "        \"cv_results\": cv_results,\n",
    "    }\n",
    "\n",
    "    summary_path = os.path.join(summary_dir, \"cv_results.json\")\n",
    "    summary_payload_serializable = _to_serializable(summary_payload)\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(summary_payload_serializable, f, indent=2)\n",
    "\n",
    "    print(f\"[CV] Saved CV summary to {summary_path}\")\n",
    "    print(\"\")\n",
    "    print(\n",
    "        f\"[CV] All folds completed in {time.time() - t_global_start:.1f}s \"\n",
    "        f\"for {n_splits} folds and targets: {TARGETS}\"\n",
    "    )\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return fold_models, cv_results, transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04799007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] Using 'id' as group column and dropping it from features\n",
      "[CV] Using GroupKFold over group_col='id'\n",
      "[CV] Starting XGBoost cross validation\n",
      "[CV] Splitter: GroupKFold(n_splits=5, group_col='id')\n",
      "[CV] Total samples: 1000\n",
      "[CV] Targets: ['n2o', 'no3', 'yield', 'soc']\n",
      "================================================================================\n",
      "[CV] Fitting target transformations on full dataset ...\n",
      "[CV] Target transformations done in 0.0s\n",
      "[CV] Moving features to CPU (numpy float32) ...\n",
      "[CV] X feature shape (without group_col): (1000, 62), converted in 0.0s\n",
      "[CV] Feature columns used: ['soil', 'climate', 'cropping_systems', 'crop_rotation', 'n_synth_type', 'n_org_type', 'n_org_replication', 'n_synth_replication', 'irrigation', 'manu_depth', 'n_org_amount', 'n_synthamount', 'fert_amount_1', 'fert_amount_2', 'fert_amount_3', 'manu_amount_1', 'manu_amount_2', 'manu_amount_3', 'prec_days', 'total_nitrogen', 'total_precipitation_year', 'total_average_temperature_year', 'total_precipitation_growing_season', 'total_average_temperature_growing_season', 'total_precipitation_autum', 'total_average_temperature_autum', 'total_precipitation_winter', 'total_average_temperature_winter', 'total_precipitation_spring', 'total_average_temperature_spring', 'bd', 'corg', 'norg', 'sand', 'silt', 'clay', 'ph', 'sks', 'wcmax', 'wcmin', 'total_precipitation_3_after_fert_1', 'total_precipitation_3_after_fert_2', 'total_precipitation_3_after_fert_3', 'total_precipitation_3_after_manu_1', 'total_precipitation_3_after_manu_2', 'total_precipitation_3_after_manu_3', 'total_precipitation_7_before_fert_1', 'total_precipitation_7_before_fert_2', 'total_precipitation_7_before_fert_3', 'total_precipitation_7_before_manu_1', 'total_precipitation_7_before_manu_2', 'total_precipitation_7_before_manu_3', 'synth_org_ratio', 'precipitation_clay_interaction', 'precip_n_interaction', 'fert_amount_1_sq', 'fert_amount_2_sq', 'fert_amount_3_sq', 'manu_amount_1_sq', 'manu_amount_2_sq', 'manu_amount_3_sq', 'total_nitrogen_sq']\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "[CV] Fold 1/5 - train samples: 800, val samples: 200\n",
      "================================================================================\n",
      "[CV][Fold 1] Target 'n2o' - preparing data ...\n",
      "[CV][Fold 1] Target 'n2o' - training XGBoost ...\n",
      "[CV][Fold 1] Target 'n2o' done in 0.7s | val RMSE: 0.3450 MAE: 0.2612 R2: 0.5200\n",
      "[CV][Fold 1] Target 'no3' - preparing data ...\n",
      "[CV][Fold 1] Target 'no3' - training XGBoost ...\n",
      "[CV][Fold 1] Target 'no3' done in 0.7s | val RMSE: 21.5195 MAE: 12.5316 R2: 0.7372\n",
      "[CV][Fold 1] Target 'yield' - preparing data ...\n",
      "[CV][Fold 1] Target 'yield' - training XGBoost ...\n",
      "[CV][Fold 1] Target 'yield' done in 2.7s | val RMSE: 1693.2096 MAE: 1391.6628 R2: 0.6929\n",
      "[CV][Fold 1] Target 'soc' - preparing data ...\n",
      "[CV][Fold 1] Target 'soc' - training XGBoost ...\n",
      "[CV][Fold 1] Target 'soc' done in 1.2s | val RMSE: 357.9093 MAE: 280.0595 R2: 0.7088\n",
      "[CV] Completed fold 1/5 in 5.4s\n",
      "\n",
      "================================================================================\n",
      "[CV] Fold 2/5 - train samples: 800, val samples: 200\n",
      "================================================================================\n",
      "[CV][Fold 2] Target 'n2o' - preparing data ...\n",
      "[CV][Fold 2] Target 'n2o' - training XGBoost ...\n",
      "[CV][Fold 2] Target 'n2o' done in 0.6s | val RMSE: 0.3872 MAE: 0.2571 R2: 0.6769\n",
      "[CV][Fold 2] Target 'no3' - preparing data ...\n",
      "[CV][Fold 2] Target 'no3' - training XGBoost ...\n",
      "[CV][Fold 2] Target 'no3' done in 0.7s | val RMSE: 23.0580 MAE: 12.1255 R2: 0.5065\n",
      "[CV][Fold 2] Target 'yield' - preparing data ...\n",
      "[CV][Fold 2] Target 'yield' - training XGBoost ...\n",
      "[CV][Fold 2] Target 'yield' done in 1.2s | val RMSE: 1674.0111 MAE: 1402.3469 R2: 0.6961\n",
      "[CV][Fold 2] Target 'soc' - preparing data ...\n",
      "[CV][Fold 2] Target 'soc' - training XGBoost ...\n",
      "[CV][Fold 2] Target 'soc' done in 1.5s | val RMSE: 427.9513 MAE: 327.2066 R2: 0.3884\n",
      "[CV] Completed fold 2/5 in 4.1s\n",
      "\n",
      "================================================================================\n",
      "[CV] Fold 3/5 - train samples: 800, val samples: 200\n",
      "================================================================================\n",
      "[CV][Fold 3] Target 'n2o' - preparing data ...\n",
      "[CV][Fold 3] Target 'n2o' - training XGBoost ...\n",
      "[CV][Fold 3] Target 'n2o' done in 0.8s | val RMSE: 0.5226 MAE: 0.3259 R2: 0.5038\n",
      "[CV][Fold 3] Target 'no3' - preparing data ...\n",
      "[CV][Fold 3] Target 'no3' - training XGBoost ...\n",
      "[CV][Fold 3] Target 'no3' done in 0.8s | val RMSE: 43.0617 MAE: 31.1503 R2: 0.4275\n",
      "[CV][Fold 3] Target 'yield' - preparing data ...\n",
      "[CV][Fold 3] Target 'yield' - training XGBoost ...\n",
      "[CV][Fold 3] Target 'yield' done in 0.9s | val RMSE: 1422.0343 MAE: 1140.6907 R2: 0.7044\n",
      "[CV][Fold 3] Target 'soc' - preparing data ...\n",
      "[CV][Fold 3] Target 'soc' - training XGBoost ...\n",
      "[CV][Fold 3] Target 'soc' done in 0.8s | val RMSE: 412.5903 MAE: 345.2142 R2: 0.7635\n",
      "[CV] Completed fold 3/5 in 3.3s\n",
      "\n",
      "================================================================================\n",
      "[CV] Fold 4/5 - train samples: 800, val samples: 200\n",
      "================================================================================\n",
      "[CV][Fold 4] Target 'n2o' - preparing data ...\n",
      "[CV][Fold 4] Target 'n2o' - training XGBoost ...\n",
      "[CV][Fold 4] Target 'n2o' done in 0.5s | val RMSE: 0.4226 MAE: 0.2830 R2: 0.5495\n",
      "[CV][Fold 4] Target 'no3' - preparing data ...\n",
      "[CV][Fold 4] Target 'no3' - training XGBoost ...\n",
      "[CV][Fold 4] Target 'no3' done in 1.0s | val RMSE: 25.2047 MAE: 10.6041 R2: 0.5990\n",
      "[CV][Fold 4] Target 'yield' - preparing data ...\n",
      "[CV][Fold 4] Target 'yield' - training XGBoost ...\n",
      "[CV][Fold 4] Target 'yield' done in 0.7s | val RMSE: 1660.1976 MAE: 1346.9365 R2: 0.6782\n",
      "[CV][Fold 4] Target 'soc' - preparing data ...\n",
      "[CV][Fold 4] Target 'soc' - training XGBoost ...\n",
      "[CV][Fold 4] Target 'soc' done in 1.3s | val RMSE: 625.9431 MAE: 513.4963 R2: 0.4490\n",
      "[CV] Completed fold 4/5 in 3.6s\n",
      "\n",
      "================================================================================\n",
      "[CV] Fold 5/5 - train samples: 800, val samples: 200\n",
      "================================================================================\n",
      "[CV][Fold 5] Target 'n2o' - preparing data ...\n",
      "[CV][Fold 5] Target 'n2o' - training XGBoost ...\n",
      "[CV][Fold 5] Target 'n2o' done in 1.7s | val RMSE: 0.4281 MAE: 0.2916 R2: 0.7006\n",
      "[CV][Fold 5] Target 'no3' - preparing data ...\n",
      "[CV][Fold 5] Target 'no3' - training XGBoost ...\n",
      "[CV][Fold 5] Target 'no3' done in 0.8s | val RMSE: 50.8535 MAE: 29.5493 R2: 0.3102\n",
      "[CV][Fold 5] Target 'yield' - preparing data ...\n",
      "[CV][Fold 5] Target 'yield' - training XGBoost ...\n",
      "[CV][Fold 5] Target 'yield' done in 1.4s | val RMSE: 1629.8877 MAE: 1332.8165 R2: 0.6558\n",
      "[CV][Fold 5] Target 'soc' - preparing data ...\n",
      "[CV][Fold 5] Target 'soc' - training XGBoost ...\n",
      "[CV][Fold 5] Target 'soc' done in 0.9s | val RMSE: 429.5339 MAE: 361.5679 R2: 0.5588\n",
      "[CV] Completed fold 5/5 in 4.9s\n",
      "\n",
      "================================================================================\n",
      "[CV] Aggregating metrics across folds\n",
      "================================================================================\n",
      "[CV][n2o] RMSE: 0.4211 ± 0.0588 | MAE: 0.2837 ± 0.0247 | R2: 0.5902 ± 0.0822\n",
      "[CV][no3] RMSE: 32.7395 ± 11.9253 | MAE: 19.1922 ± 9.1468 | R2: 0.5161 ± 0.1457\n",
      "[CV][yield] RMSE: 1615.8680 ± 99.0914 | MAE: 1322.8907 ± 94.7802 | R2: 0.6855 ± 0.0171\n",
      "[CV][soc] RMSE: 450.7856 ± 91.3653 | MAE: 365.5089 ± 78.8623 | R2: 0.5737 ± 0.1445\n",
      "[CV] Saved CV summary to experiments_cv/multi_target_xgb_cv/summary/cv_results.json\n",
      "\n",
      "[CV] All folds completed in 21.5s for 5 folds and targets: ['n2o', 'no3', 'yield', 'soc']\n",
      "================================================================================\n",
      "CPU times: user 47 s, sys: 558 ms, total: 47.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fold_models, cv_results, transformers = train_xgb_models_cv(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_splits=5,\n",
    "    group_col=\"id\",          # used only for splitting, not as feature\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    num_boost_round=10_000,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=False,\n",
    "    log_to_mlflow=False,\n",
    "    base_dir=\"experiments_cv\",\n",
    "    experiment_name=\"multi_target_xgb_cv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0201936-cd9d-4628-8ca2-047a4c16ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afb769-0385-4cb4-9688-3ae94023e432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e548674-a649-4eb6-9f7c-4f433beeb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path=\"experiments_cv/multi_target_xgb_cv/experiments.jsonl\"\n",
    "rows=[]\n",
    "with open(path, 'r') as f:\n",
    "    for line in f:\n",
    "        rec=json.loads(line)\n",
    "        run_name=rec.get(\"run_name\")\n",
    "        fold=run_name.split(\"_\")[-1] if \"_\" in run_name else run_name\n",
    "        fold = int(fold.replace(\"fold\", \"\"))\n",
    "        metrics=rec.get(\"metrics\",{})\n",
    "        for target, m in metrics.items():\n",
    "            rows.append({\n",
    "                \"target\": target,\n",
    "                \"fold\": fold,\n",
    "                \"rmse\": m.get(\"rmse\"),\n",
    "                \"mae\": m.get(\"mae\"),\n",
    "                \"r2\": m.get(\"r2\"),\n",
    "            })\n",
    "df=pd.DataFrame(rows)\n",
    "\n",
    "# compute oof per target\n",
    "oof_list=[]\n",
    "for target, grp in df.groupby(\"target\"):\n",
    "    oof_list.append({\n",
    "        \"target\": target,\n",
    "        \"fold\": \"OOF\",\n",
    "        \"rmse\": grp[\"rmse\"].mean(),\n",
    "        \"mae\": grp[\"mae\"].mean(),\n",
    "        \"r2\": grp[\"r2\"].mean(),\n",
    "    })\n",
    "df_oof=pd.DataFrame(oof_list)\n",
    "\n",
    "final_df=pd.concat([df, df_oof], ignore_index=True)\n",
    "final_df.sort_values(['target','fold'] , inplace = True)\n",
    "final_df = final_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f5eb537-eed4-4268-98e4-762a7ffe9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('experiments_cv/experiments_cv.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e331c09-2801-44ad-9028-85fffc230984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mldndc-env)",
   "language": "python",
   "name": "mldndc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
